# Mini AI Analyst

A comprehensive data analysis and machine learning platform that provides automated data profiling, model training, predictions, and AI-powered insights using Google's Gemini LLM.

## 🚀 Features

- **Data Upload & Processing**: Upload CSV files and get instant data profiling
- **Automated Data Analysis**: Comprehensive statistical analysis, outlier detection, and correlation analysis
- **Machine Learning Pipeline**: Train classification and regression models with multiple algorithms
- **Model Predictions**: Make predictions on new data with confidence scores
- **Natural Language Summaries**: Get detailed insights and recommendations in plain English
- **AI-Powered Analysis**: Advanced insights generated by Google's Gemini 2.0 Flash LLM
- **Export Capabilities**: Export comprehensive reports and analysis results
- **User Authentication**: Secure user management with Supabase

## 🧠 AI Analysis Features

The platform now includes an advanced AI Analysis section powered by Google's Gemini LLM that provides:

- **Comprehensive AI Analysis**: Natural language analysis of your dataset and model performance
- **Enhanced Insights**: Deeper insights that go beyond basic statistics
- **Business Recommendations**: Actionable business recommendations based on data insights
- **Technical Recommendations**: Technical recommendations for improving models and data quality
- **Risk Assessment**: Identification of potential risks and concerns
- **Opportunities**: Business opportunities and areas for further investigation

## 🛠️ Technology Stack

### Backend
- **FastAPI**: Modern Python web framework
- **Pandas & NumPy**: Data manipulation and analysis
- **Scikit-learn**: Machine learning algorithms
- **XGBoost**: Gradient boosting framework
- **SHAP**: Model interpretability
- **Google Generative AI**: Gemini LLM integration
- **Supabase**: Database and authentication
- **Celery**: Background task processing

### Frontend
- **React**: User interface framework
- **TypeScript**: Type-safe JavaScript
- **Tailwind CSS**: Utility-first CSS framework
- **Lucide React**: Beautiful icons
- **React Hot Toast**: Toast notifications

## 📦 Installation

### Prerequisites
- Python 3.10+
- Node.js 16+
- Docker (optional)

### Backend Setup
```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Frontend Setup
```bash
cd frontend
npm install
```

### Environment Configuration
Create a `.env` file in the root directory:
```env
gemini_llm_api_key=your_gemini_api_key_here
```

## 🚀 Running the Application

### Development Mode
```bash
# Backend
cd backend
source .venv/bin/activate
uvicorn app.main:app --reload --port 8000

# Frontend
cd frontend
npm start
```

### Docker
```bash
docker-compose up --build
```

## 📊 API Endpoints

### 1. Upload Data
```http
POST /api/v1/upload
```

### 2. Data Profiling
```http
GET /api/v1/profile/{session_id}
```

### 3. Model Training
```http
POST /api/v1/train/{session_id}
```

### 4. Predictions
```http
POST /api/v1/predict/{model_id}
```

### 5. Summary
```http
GET /api/v1/summary/{session_id}
```

### 6. AI Analysis
```http
GET /api/v1/ai-analysis/{session_id}
```

### 7. Export
```http
GET /api/v1/export/report/{session_id}
```

## 🧪 Testing

### Backend Tests
```bash
cd backend
pytest tests/ -v
```

### Frontend Tests
```bash
cd frontend
npm test
```

## 📊 Sample Use Case

1. **Upload Dataset**: User uploads a customer churn dataset
2. **Data Profiling**: System automatically analyzes the data and provides insights
3. **Model Training**: User selects "churn" as target and trains a classification model
4. **Predictions**: User can make predictions on new customer data
5. **Summary**: System provides natural language summary of findings
6. **AI Analysis**: Advanced AI-powered insights using Gemini LLM

## 🔧 Configuration

### Environment Variables
- `MAX_FILE_SIZE`: Maximum file size in bytes (default: 50MB)
- `MODEL_STORAGE_PATH`: Path to store trained models
- `UPLOAD_STORAGE_PATH`: Path to store uploaded files
- `CORS_ORIGINS`: Allowed CORS origins for frontend
- `GEMINI_LLM_API_KEY`: Google Gemini API key for AI analysis

## 🚀 Deployment

### Production Docker
```bash
docker-compose -f docker-compose.prod.yml up --build
```

### Cloud Deployment
The application is designed to be easily deployable to:
- AWS ECS/Fargate
- Google Cloud Run
- Azure Container Instances
- Heroku

## 📝 Assumptions and Limitations

### Assumptions
- CSV files are well-formatted with headers
- Target columns are clearly identifiable
- Users have basic understanding of ML concepts
- File uploads are from trusted sources

### Limitations
- Maximum file size: 50MB
- Supported formats: CSV only
- Model types: Classification and Regression
- No real-time streaming for large datasets
- Basic authentication (session-based)
- AI Analysis requires valid Gemini API key

### Note
- Use small datasets for tests as large dataset requires time for analysis

## 🎯 Optional Features Implemented

- ✅ Background job processing with Celery
- ✅ PostgreSQL database for metadata storage
- ✅ S3-compatible storage for files
- ✅ Model versioning and management
- ✅ Comprehensive data validation
- ✅ Automated feature engineering
- ✅ Model interpretability with SHAP
- ✅ Export functionality (JSON, CSV, ZIP)
- ✅ AI-powered analysis with Gemini LLM
- ✅ Real-time progress tracking
- ✅ Error handling and recovery
- ✅ Responsive design
- ✅ Dark mode support (planned)

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.

