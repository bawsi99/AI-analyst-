# Mini AI Analyst

A comprehensive data analysis and machine learning platform that provides automated data profiling, model training, predictions, and AI-powered insights using Google's Gemini LLM.

## üöÄ Features

- **Data Upload & Processing**: Upload CSV files and get instant data profiling
- **Automated Data Analysis**: Comprehensive statistical analysis, outlier detection, and correlation analysis
- **Machine Learning Pipeline**: Train classification and regression models with multiple algorithms
- **Model Predictions**: Make predictions on new data with confidence scores
- **Natural Language Summaries**: Get detailed insights and recommendations in plain English
- **AI-Powered Analysis**: Advanced insights generated by Google's Gemini 2.0 Flash LLM
- **Export Capabilities**: Export comprehensive reports and analysis results
- **User Authentication**: Secure user management with Supabase

## üß† AI Analysis Features

The platform now includes an advanced AI Analysis section powered by Google's Gemini LLM that provides:

- **Comprehensive AI Analysis**: Natural language analysis of your dataset and model performance
- **Enhanced Insights**: Deeper insights that go beyond basic statistics
- **Business Recommendations**: Actionable business recommendations based on data insights
- **Technical Recommendations**: Technical recommendations for improving models and data quality
- **Risk Assessment**: Identification of potential risks and concerns
- **Opportunities**: Business opportunities and areas for further investigation

## üõ†Ô∏è Technology Stack

### Backend
- **FastAPI**: Modern Python web framework
- **Pandas & NumPy**: Data manipulation and analysis
- **Scikit-learn**: Machine learning algorithms
- **XGBoost**: Gradient boosting framework
- **SHAP**: Model interpretability
- **Google Generative AI**: Gemini LLM integration
- **Supabase**: Database and authentication
- **Celery**: Background task processing

### Frontend
- **React**: User interface framework
- **TypeScript**: Type-safe JavaScript
- **Tailwind CSS**: Utility-first CSS framework
- **Lucide React**: Beautiful icons
- **React Hot Toast**: Toast notifications

## üì¶ Installation

### Prerequisites
- Python 3.10+
- Node.js 16+
- Docker (optional)

### Backend Setup
```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Frontend Setup
```bash
cd frontend
npm install
```

### Environment Configuration
Create a `.env` file in the root directory:
```env
# Required for AI Analysis
GEMINI_LLM_API_KEY=your_gemini_api_key_here

# Supabase Configuration (Required)
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# Database Configuration (Optional - defaults to local PostgreSQL)
DATABASE_URL=postgresql://user:password@localhost/ai_analyst

# Redis Configuration (Optional - for background tasks)
REDIS_URL=redis://localhost:6379/0

# S3 Storage (Optional)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=your_bucket_name
```

## üöÄ Running the Application

### Development Mode
```bash
# Backend
cd backend
source .venv/bin/activate
uvicorn app.main:app --reload --port 8000

# Frontend
cd frontend
npm start
```

### Docker
```bash
docker-compose up --build
```

## üìä API Endpoints

### 1. Upload Data
```http
POST /api/v1/upload
```

### 2. Data Profiling
```http
GET /api/v1/profile/{session_id}
```

### 3. Model Training
```http
POST /api/v1/train/{session_id}
```

### 4. Predictions
```http
POST /api/v1/predict/{model_id}
```

### 5. Summary
```http
GET /api/v1/summary/{session_id}
```

### 6. AI Analysis
```http
GET /api/v1/ai-analysis/{session_id}
```

### 7. Export
```http
GET /api/v1/export/report/{session_id}
```

### 8. Authentication
```http
POST /api/v1/auth/register
POST /api/v1/auth/login
GET /api/v1/auth/profile
```

### 9. Dashboard
```http
GET /api/v1/dashboard/stats
GET /api/v1/dashboard/sessions
GET /api/v1/dashboard/models
GET /api/v1/dashboard/predictions
```

## üß™ Testing

### Backend Tests
```bash
cd backend
pytest -v
```

### Frontend Tests
```bash
cd frontend
npm test
```

## üìä Sample Use Case

1. **Upload Dataset**: User uploads a customer churn dataset
2. **Data Profiling**: System automatically analyzes the data and provides insights
3. **Model Training**: User selects "churn" as target and trains a classification model
4. **Predictions**: User can make predictions on new customer data
5. **Summary**: System provides natural language summary of findings
6. **AI Analysis**: Advanced AI-powered insights using Gemini LLM

## üîß Configuration

### Environment Variables
- `MAX_FILE_SIZE`: Maximum file size in bytes (default: 50MB)
- `MODEL_STORAGE_PATH`: Path to store trained models
- `UPLOAD_STORAGE_PATH`: Path to store uploaded files
- `CORS_ORIGINS`: Allowed CORS origins for frontend
- `GEMINI_LLM_API_KEY`: Google Gemini API key for AI analysis
- `SUPABASE_URL`: Supabase project URL
- `SUPABASE_ANON_KEY`: Supabase anonymous key
- `SUPABASE_SERVICE_ROLE_KEY`: Supabase service role key
- `DATABASE_URL`: PostgreSQL database connection string
- `REDIS_URL`: Redis connection string for background tasks

## üöÄ Deployment

### Production Docker
```bash
# Use the existing docker-compose.yml for production
docker-compose up --build
```

### Cloud Deployment
The application is designed to be easily deployable to:
- AWS ECS/Fargate
- Google Cloud Run
- Azure Container Instances
- Heroku

## üìù Assumptions and Limitations

### Assumptions
- CSV files are well-formatted with headers
- Target columns are clearly identifiable
- Users have basic understanding of ML concepts
- File uploads are from trusted sources

### Limitations
- Maximum file size: 50MB
- Supported formats: CSV only
- Model types: Classification and Regression
- No real-time streaming for large datasets
- Basic authentication (session-based)
- AI Analysis requires valid Gemini API key

### Note
- Use small datasets for tests as large dataset requires time for analysis

## üéØ Optional Features Implemented

- ‚úÖ Background job processing with Celery
- ‚úÖ PostgreSQL database for metadata storage
- ‚úÖ S3-compatible storage for files
- ‚úÖ Model versioning and management
- ‚úÖ Comprehensive data validation
- ‚úÖ Automated feature engineering
- ‚úÖ Model interpretability with SHAP
- ‚úÖ Export functionality (JSON, CSV, ZIP)
- ‚úÖ AI-powered analysis with Gemini LLM
- ‚úÖ Real-time progress tracking
- ‚úÖ Error handling and recovery
- ‚úÖ Responsive design
- ‚úÖ Dark mode support (planned)

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

